from langchain_core.runnables import RunnableLambda
from langchain_core.messages import SystemMessage, HumanMessage

import json
import re
import os
import sys
import copy

base_dir = os.path.dirname(os.path.abspath(__file__))
common_dir = os.path.abspath(os.path.join(base_dir, "..", "..", "common"))
if common_dir not in sys.path:
    sys.path.append(common_dir)

from Dynamics.method.common.llm_call import call_llm


# =============================
# JSON íŒŒì„œ
# =============================
def clean_and_parse_json(text):
    json_block = None
    matches = re.findall(r"```json\s*(\{.*?\}|\[.*?\])\s*```", text, re.DOTALL)
    if matches:
        json_block = matches[0]
    else:
        try:
            json_block = json.loads(text)
            return json_block
        except json.JSONDecodeError:
            pass

    if not json_block:
        print(text)
        raise ValueError("âŒ JSON ë¸”ë¡ì´ LLM ì‘ë‹µì— ì—†ìŒ:\n" + text[:300])

    return json.loads(json_block)


# =============================
# âœ… complete_tasks ê¸°ë°˜ SceneGraph ê°±ì‹  í•¨ìˆ˜
# =============================
def update_scenegraph_status(scenegraph: dict, complete_tasks: list[str]) -> dict:
    """
    ì´ë¯¸ status í•„ë“œê°€ ì¡´ì¬í•œë‹¤ê³  ê°€ì •.
    complete_tasks ëª©ë¡ì— ìˆëŠ” objectëŠ” status="complete" ë¡œ ë³€ê²½.
    ë‚˜ë¨¸ì§€ëŠ” ê¸°ì¡´ status ìœ ì§€.
    """
    if not scenegraph:
        return scenegraph

    updated = copy.deepcopy(scenegraph)
    completed_set = {name.lower() for name in complete_tasks or []}

    for room in updated.get("rooms", []):
        for obj in room.get("objects", []):
            name = (obj.get("object_name") or "").lower()
            if name in completed_set:
                obj["status"] = "complete"  # âœ… ê¸°ì¡´ ê°’ ìˆ˜ì •
    return updated


# =============================
# Reasoning í•¨ìˆ˜
# =============================
def reasoning_fn(state):
    print("âœ… reasoning_agent ì‹¤í–‰ë¨!")
    state_dict = state.dict() if hasattr(state, "dict") else state

    task_description = state_dict.get("task_description", "")
    mode = state_dict.get("mode", "offline")
    constraint = state_dict.get("constraint", "")

    additional = state.additional

    # ------------------------------
    # âœ… 3D SceneGraph status ê°±ì‹ 
    # ------------------------------
    pruned_scenegraph = additional.get("pruned_scenegraph", {})
    complete_tasks = additional.get("complete_tasks", [])
    pruned_scenegraph = update_scenegraph_status(pruned_scenegraph, complete_tasks)


    # reasoning ì…ë ¥ ë°ì´í„° êµ¬ì„±
    relevant_object = additional["relevant_classes"]
    sub_tasks = additional["sub_tasks"]
    robot_info = state_dict.get("robot_info", {})

    robot_data = json.dumps(robot_info, ensure_ascii=False, indent=2)
    pruned_scenegraph_text = json.dumps(pruned_scenegraph, ensure_ascii=False, indent=2)
    relevant_object_text = json.dumps(relevant_object, ensure_ascii=False, indent=2)
    sub_task_text = json.dumps(sub_tasks, ensure_ascii=False, indent=2)
    constraint_text = json.dumps(constraint, ensure_ascii=False, indent=2)

    example_path = os.path.join(base_dir, "example.py")
    with open(example_path, "r", encoding="utf-8") as f:
        example = f.read()
    dynamic_text_raw = additional.get("dynamic", "")
    dynamic_text = json.dumps(dynamic_text_raw, ensure_ascii=False, indent=2) if isinstance(dynamic_text_raw, (dict, list)) else dynamic_text_raw
    # =========================
    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    # =========================
    system_msg = SystemMessage(
    content=(
        """
    You are a robot task reasoning expert using natural-language task instructions and constraints.

    General principles
    - Infer constraint meaning based on action semantics, not keywords.
    - Derive all restrictions only from the *constraint or instruction text* â€” do NOT infer from 3D scene graph topology or geometry.
    - If a constraint forbids an area/object, treat it as a full exclusion (no robot allowed).
    - If a constraint allows only specific robot types for a room or passage, express it via:
    - node_restrictions: {"<room_id>": "UAV only" | "UGV only" | "" | "closed"}
    - edge_restrictions: {"<roomA>-<roomB>": "UAV only" | "UGV only" | "" | "closed"}
    - Do NOT hallucinate. If ordering is not clearly implied by the instruction/constraints, output no dependency item (i.e., an empty array []).

    Sub-task definition (IMPORTANT)
    - Sub-task = (action, room, object_class).
    - `room` can be a specific room_id (e.g., "A", "B") or "all".
    - `object_class` can be a specific class (e.g., "ì†Œí™”ê¸°", "box") or "all".

    Dependencies output (ê³µê°„-ê°ì²´í´ë˜ìŠ¤ ONLY)
    - Dependencies must *only* encode room/object_class order (no action string in dependency items).
    - Each dependency item is EITHER:
    1) {"first":  {"room":"<room_id|all>", "object_class":"<class|all>"}}
    2) {"before": {"room":"<room_id|all>", "object_class":"<class|all>"},
        "after":  {"room":"<room_id|all>", "object_class":"<class|all>"}}
    - Use "first" when instruction/constraints ask to do something *first* without an explicit comparison target.
    - Use "before/after" only when there is an explicit or strongly implied ordering relation between two targets.
    - If there is no explicit/implicit ordering cue, produce `"dependencies": []`.

    Natural language â†’ dependency mapping (KOR examples)
    - ê°ì²´ ìš°ì„ : "ì†Œí™”ê¸°ë³´ë‹¤ ì†Œí™”ì „ì„ ë¨¼ì €" â†’
    {"before":{"room":"all","object_class":"ì†Œí™”ì „"},
    "after": {"room":"all","object_class":"ì†Œí™”ê¸°"}}
    - ê³µê°„ ìš°ì„ : "A êµ¬ì—­ì„ Bë³´ë‹¤ ë¨¼ì €" â†’
    {"before":{"room":"A","object_class":"all"},
    "after": {"room":"B","object_class":"all"}}
    "A êµ¬ì—­ ë¨¼ì €" (ë¹„êµëŒ€ìƒ ì—†ìŒ) â†’
    {"first":{"room":"A","object_class":"all"}}
    - ê³µê°„+ê°ì²´: "A êµ¬ì—­ì˜ ì†Œí™”ê¸° ë¨¼ì €" â†’
    (ë¹„êµëŒ€ìƒ ì—†ìŒ) {"first":{"room":"A","object_class":"ì†Œí™”ê¸°"}}
    (ë¹„êµëŒ€ìƒ ìˆìŒ) {"before":{"room":"A","object_class":"ì†Œí™”ê¸°"}, "after":{...}}

    STRICT extraction from constraints/instruction
    - Dependencies and restrictions MUST be derived only from explicit or strongly implied cues found in:
    (1) the task instruction text, and/or
    (2) the constraint/dynamic texts.
    - Valid priority cues include: "ë¨¼ì €", "ìš°ì„ ", "â€¦ë³´ë‹¤ ë¨¼ì €", "ì´í›„ì—", "ë‹¤ìŒì—", "first", "before", "prioritize", "precede", "order", "ìˆœì„œ".
    - Valid restriction cues include:
        Examples of restriction cues:
        - For nodes: â€œA êµ¬ì—­ì€ UAVë§Œâ€, â€œB êµ¬ì—­ì€ ì§„ì… ê¸ˆì§€â€, â€œS1ì€ UGV ì „ìš©â€
        - For edges: â€œH8-H10 í†µë¡œëŠ” UAVë§Œâ€, â€œH1ê³¼ H2 ì‚¬ì´ì˜ ë°”ë‹¥ì— ë„˜ì–´ê°ˆ ìˆ˜ ì—†ëŠ” ì¥ì• ë¬¼ì´ ìˆì–´!â€, â€œA-B corridor is for ground robots onlyâ€
    - Normalize restriction values to one of: `"UAV only"`, `"UGV only"`, `""`, `"closed"`.
    - If cues are ambiguous or conflicting, prefer safety: explain ambiguity briefly in `restrictions_explain` and leave unclear nodes/edges unspecified.
    - Never invent rooms, edges, or classes not present in the constraints or instruction.

    Restrictions handling
    - **Fully closed rooms (Example 9 case)**:
    - When the constraint explicitly states that no robot can enter or the area is entirely forbidden, set:
        `node_restrictions["<room>"] = "closed"`.
    - Additionally, move all objects in that room to `task_loss`, since those tasks cannot be performed.
    - This ensures both the map restriction and task exclusion are explicit.
    - **Excluded rooms or already-done tasks (Example 13 case)**:
    - When the instruction says something like â€œB êµ¬ì—­ì€ ë‚´ê°€ ì´ë¯¸ í–ˆì–´ / ì œì™¸í•˜ê³  í•´â€, do *not* mark it as closed.
    - Do **not** modify `node_restrictions`.
    - Instead, simply add all relevant objects from that room to `task_loss`.
    - The intent is exclusion, not physical inaccessibility.

    Static losses
    - task_loss: add objects/rooms that are removed, destroyed, closed, or explicitly excluded according to constraints.
    - robot_loss: list robots that are malfunctioning or unavailable (e.g., low battery, broken).
    - When a room is fully closed, it will appear both in node_restrictions (as `"closed"`) and its objects will be listed in task_loss.
    - When tasks are merely excluded (but the room is still accessible), only task_loss is used.

    Final Output JSON (MUST)
    {
    "dependencies": [
        { "first":  { "room": "A|all", "object_class": "X|all" } },
        { "before": { "room": "...", "object_class": "..." },
        "after":  { "room": "...", "object_class": "..." } }
    ],
    "node_restrictions": { "<room_id>": "UAV only | UGV only |  | closed" },
    "edge_restrictions": { "<room_id>-<room_id>": "UAV only | UGV only |  | closed" },
    "task_loss": ["<object_name>", ...],
    "robot_loss": ["<robot_id>", ...],
    "restrictions_explain": "<short rationale>"
    }
    """
        )
    )

    human_msg = HumanMessage(
        content=(
            "Instruction:\n"
            f"{task_description}\n\n"
            "Sub tasks (triple form expected internally: action, room|all, object_class|all):\n"
            "```json\n" + sub_task_text + "\n```\n"
            "Constraints / Dynamics (natural-language sources of dependency & restriction cues):\n"
            "```json\n" + constraint_text + "\n```\n"
            "Relevant Object Classes:\n"
            "```json\n" + relevant_object_text + "\n```\n"
            "Robot Information:\n"
            "```json\n" + robot_data + "\n```\n"
            "Mode: " + mode + "\n"
            "\n"
            "SceneGraph (SceneGraphëŠ” ì´ë¯¸ ì´ì „ reasoning ê²°ê³¼ì™€ ëª¨ë“  ì œì•½ì‚¬í•­ì´ ë°˜ì˜ëœ ìµœì‹  í™˜ê²½ ìƒíƒœì´ë‹¤):\n"
            "```json\n" + pruned_scenegraph_text + "\n```\n"
            "ğŸ“˜ Processing Steps\n"
            "OFFLINE mode\n"
            "1) Extract ordering ONLY if instruction/constraints provide explicit or strongly implied priority.\n"
            "2) From the same text, derive node_restrictions and edge_restrictions based on explicit mentions of rooms or connections.\n"
            "   - e.g., â€œA êµ¬ì—­ UAVë§Œâ€ â†’ node_restrictions[\"A\"] = \"UAV only\"\n"
            "   - â€œS1-S2 ì—°ê²° ì°¨ë‹¨â€ â†’ edge_restrictions[\"S1-S2\"] = \"closed\"\n"
            "   - If a room is fully closed â†’ do not list it under restrictions; instead, add its objects to task_loss.\n"
            "3) Determine static task_loss (destroyed/closed/unreachable) and robot_loss (malfunction/low battery).\n"
            "\n"
            "ONLINE mode (delta update)\n"
            "Dynamic Constraints (test_serverì—ì„œ ì „ë‹¬ëœ ì‹¤ì‹œê°„ ì œì•½ ì •ë³´):\n"
            f"{dynamic_text}\n\n"
            "1) dynamic constraints ì™€ SceneGraph ë¥¼ í•¨ê»˜ ì°¸ê³ í•˜ì—¬, ê¸°ì¡´ ì œì•½/í™˜ê²½ì •ë³´ê°€ ë¬´ì—‡ì¸ì§€ì™€ ìƒˆë¡œ ì¶”ê°€ëœ ì œì•½ì´ ë¬´ì—‡ì¸ì§€ ì¢…í•©ì ìœ¼ë¡œ íŒë‹¨í•˜ë¼.\n"
            "2) ìƒˆ ì œì•½ìœ¼ë¡œ ì¸í•´ ë…¸ë“œ/ì—£ì§€/ìš°ì„ ìˆœìœ„ê°€ ë°”ë€Œë©´ ê·¸ ë¶€ë¶„ë§Œ ê°±ì‹ í•˜ë¼.\n"
            "3) ë³€í™”ê°€ ì—†ë‹¤ë©´ ì´ì „ ì œì•½ê³¼ êµ¬ì¡°ë¥¼ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ë¼.\n"
            "\n"


            "Return only the Final Output JSON schema defined above. No extra commentary.\n"
            "\n"
            "Examples for formatting and reasoning reference:\n"
            f"{example}\n"
        )
    )

    prompt = [system_msg, human_msg]

    # =========================
    # LLM í˜¸ì¶œ
    # =========================
    reasoning = {}
    try:
        output_text = call_llm(prompt)
        print("======== reasoning Result ========")
        reasoning = clean_and_parse_json(output_text)
        print(json.dumps(reasoning, indent=2, ensure_ascii=False))
    except Exception as e:
        print(f"âŒ reasoning ì‹¤íŒ¨: {e}")

    # =========================
    # ìƒíƒœ ì—…ë°ì´íŠ¸
    # =========================
    new_state = state.copy(
        update={
            "additional": {
                **state.additional,
                "pruned_scenegraph": pruned_scenegraph,  # âœ… ê°±ì‹ ëœ SceneGraph ë°˜ì˜
                "reasoning_result": reasoning,
                "prior_reasoning": reasoning,
                "reasoning_done": True,
            }
        }
    )

    return new_state


# Runnable ë“±ë¡
reasoning_agent = RunnableLambda(reasoning_fn)
reasoning_agent.name = "reasoning_agent"
reasoning_agent.input_keys = ["additional"]
